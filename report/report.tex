\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\begin{document}

\title{Leveraging the Jason Belief-Desire-Intention Framework to Implement RoboCup-Playing Agents\\
}

\author{\IEEEauthorblockN{Josh Blondin}
\IEEEauthorblockA{\textit{Systems and Computer Engineering} \\
\textit{Carleton University}\\
Ottawa, Canada \\
joshblondin@cmail.carleton.ca}
\and
\IEEEauthorblockN{Thomas Ross}
\IEEEauthorblockA{\textit{Systems and Computer Engineering} \\
\textit{Carleton University}\\
Ottawa, Canada \\
thomasross@cmail.carleton.ca}
\and
\IEEEauthorblockN{Nicholas Sendyk}
\IEEEauthorblockA{\textit{Systems and Computer Engineering} \\
\textit{Carleton University}\\
Ottawa, Canada \\
nicksendyk@cmail.carleton.ca}
\and
\IEEEauthorblockN{William Tran}
\IEEEauthorblockA{\textit{Systems and Computer Engineering} \\
\textit{Carleton University}\\
Ottawa, Canada \\
williamtran5@cmail.carleton.ca}
}

\maketitle

\begin{abstract}
(J.B.) Jason is a popular AgentSpeak framework used to build and execute BDI-based agents.
In particular, we have looked into its use in developing software agents for RoboCup, an international soccer framework where the competitors are agents.
The goal of the project and this paper was to explore how to use Jason to create these agents, not necessarily to create optimized agents.
For this purpose we created three agents with different goals, desires, and movement patterns, to showcase how different agents acting individually would operate together.
\end{abstract}

\begin{IEEEkeywords}
agents, beliefs-desires-intentions, robocup, jason
\end{IEEEkeywords}

\section{Introduction (T.R.)}
RoboCup is a soccer league for robots with the goal of creating a team of
soccer-playing robots that can outperform a world-class human soccer
team~\cite{robocup-objective}. Jason is an interpreter for AgentSpeak, a
beliefs-desires-intentions programming language, that provides a framework for
multi-agent systems~\cite{jason-description}. This paper describes how our
group leveraged Jason to implement a set of agents that perform different roles
in a game of the RoboCup 2D simulation league~\cite{robocup-simulation-2d}.

\section{Integration with Jason (T.R.)}
One of the main pieces of a Jason-based agent system is the environment class,
written in Java~\cite{jason-manual}. For our implementation, this class handles
interoperability between agent definitions written in AgentSpeak and the
RoboCup simulator server. It is responsible for initializing the player
connections to the server and handling all communication over the network. This
includes receiving visual information from the simulator server and updating
the sentences perceived by each Jason agent, as well as turning Jason
agent-created action sentences into commands to send to the simulation server.

The communication between the environment class and simulation server is done
with a slightly modified version of Krislet. This version of Krislet has had
its \texttt{Brain} class removed, which is the class responsible for making
soccer-playing decisions. Additionally, it has been modified to implement
\texttt{Runnable}, meaning that it can be launched in a new thread. The
combination of these two modifications mean we can launch a Krislet instance in
a new thread, then read its memory and tell it to perform actions from other
threads, and the Krislet thread will take care of responding to messages from
the server.

From there, the environment class spawns Krislet threads and lets them
run. Jason calls the \texttt{executeAction} method when an agent wants to
perform an action, which then is responsible for requesting Krislet to send the
appropriate command to the simulation server~\cite{jason-manual}. Additionally,
whenever Jason evaluates agent plans, it calls the \texttt{getPercepts} method,
which then checks the vision of the Krislet instance to determine what percepts
the plans should be evaluated with.

\subsection{Running the Code}
Launching of the agents is handled by Jason. This can be done by downloading
and installing Jason, opening the \texttt{krislet.masj2} in jEdit, and then
clicking ``Run'' in the jEdit Jason console. The agents can also be launched
without jEdit using the instructions in the Jason FAQ~\cite{jason-faq}.

The number of agents per teams, and the type of agents on each team can be
configured in the \texttt{krislet.masj2} file according to the comments.

\section{Agents}

\subsection{Offensive agent (J.B.)}
The offensive agent utilizes predicates in order to perceive the ball, enemy goal and self goal.
Using the predicate for the ball, there are rules to see of the agent is facing the ball or at the ball are used.
There are sub-goals, with the initial sub-goal being to find the ball.
These sub-goals are what the agent desires, and then the intention of its actions are chosen from these desires.
The main goal of an offensive agent is to score a goal.
In order to achieve this, the offensive agent which was implemented follows a simple pattern: first it finds the ball, then it runs to the ball, then it finds the goal, and finally it kicks the ball to the goal.
This is a very simple implementation, as the design goal of the agent was to prove the usability of Jason's BDI framework rather than making an optimized agent.
There are still however small optimizations made which show how Jason can be used to optimize agents to make incredibly smart decisions.
When the agent dashes to the ball, it constantly turns until it is facing the ball and then only dashes.
This greatly increases its accuracy so that it won't miss the ball while maintaining a high speed.
One other example of an optimization is when the agent kicks the ball, if it does not see the enemy goal and does see its own goal, it will kick the ball in the opposite direction of its own goal.
This greatly reduces the time it would take to find the goal in which an enemy could kick the ball away, and assures that the ball will always be kicked in an appropriate direction.

\subsection{Defensive agent (N.S.)}
The defensive agent was created leveraging the Jason BDI Framework, and is designed to function like a "defender" would in soccer.
Defenders are the playmakers of soccer.
They take defensive positioning on the field and then work to pass the ball to their teammates down the field.
In this implementation of the "defensive\_agent", the agent has the initial beliefs/rules set to determine if the agent is near the ball, near its own net, and at the ball.
The agent has the initial goal of finding its positioning.
The agent continues to turn looking for its positioning (at the top of the penalty box).
The agent will run towards this position until it determines that it is there, at which point it begins to look for the ball, and runs towards the ball.
Upon arriving near the ball, this agent slows down, arrives, and then begins looking for a teammate to pass the ball to.
The agent then passes the ball (\"making a play\") and looks to return to its defensive position, and repeats the cycle.

\subsection{Goalkeeping agent (W.T.)}
In the game of soccer, the goalkeeper position's main role is to prevent the opposing team from scoring a point into their own team's goal.
This is accomplished by having them intercept the trajectory of the ball and directing it away from the vicinity of the goal.
For this implementation of a goalkeeping agent, its initial beliefs and rules regard the positioning of the agent in regard to the soccer ball and its own team's goal.
The initial goal set for this agent is to find the goal it is supposed to be defending;
this differs from defensive agents as goalkeeping agents are looking for the exact goal whereas defensive agents are looking for the top of the penalty box.
Once it is able to find the goal, it executes the corresponding plan to move towards the goal, which is satisfied once the agent is 3.0 units away from the goal flag.
It then executes the plan to locate the ball and continues to keep the ball within the agent's vision range by looping through the plan if the ball is not nearby.
If the ball falls within the 20.0 unit radius range of the agent, it will then move towards the ball.
Once next to the ball, the agent will either: 1.
Pass the ball to the furthest teammate if its own goal is not visible (to avoid self scoring) 2. Kick at the enemy goal if no teammate is visible 3.
Kick directly backwards if your own goal is visible, the enemy goal and a teammate are not 4.
Turn if none of the preconditions for the previous actions are met.
If the first three actions are taken, the agent will then execute the plan of finding its team's goal and the behavior cycles back.

\section{Testing}
\subsection{Testing Methodology (N.S.)}
Extensive manual testing was performed on each of the types of agents developed.
Initially, each variant of agent was tested individually as well as in several group settings.
A server and monitor were set up for each of the varieties of tests.

The initial test which was implemented was the "Single Agent, Single Team" test.
This testing methodology, as the name suggests, implements a single agent on only one team, and determines how the agent acts.
Positive results in this methodology occur in situations where the behaviour of the agent is exactly as expected in a deterministic setting.
As no other agents are acting upon the system, the actions of the agent should be directly known at the time of initiating a "kick-off" event.

The secondary test which was implemented was referred to as the "Utilitarianism Test".
This testing methodology follows in the footsteps of the system of utilitarian ethics~\cite{b1}, and asks "What would happen if everyone acted the same way?".
This test involves setting two teams of 5 players, all to the same variant of agent, and observing the results.
The ideology behind this methodology, is to determine if the agent still performs in the expected manner, even when many other agents may get the chance to act exactly that way before it has the opportunity to,
Positive results in this methodology occur in situations wherein the actions of each agent still follows in the premise of its design, even under the pressure of many other agents with exactly the same goals working alongside it and against it.

The tertiary test which was implemented was referred to as the teamwork test.
This test sets two teams of the same composition to face one another.
The composition was such that each team had one "goalie\_agent", two "defender\_agent"s, and two "offensive\_agent"s.
Positive results in this methodology for an agent is for each variety of agent to accomplish its goals in a manner which works in tandem with the other agents.
This is such to say, that each agent is able to perform it's intended duties without preventing other variants of agent from performing theirs.

The final test which was implemented was referred to as the "Darwinian Test".
This test is inspired by the theory of Charles Darwin regarding evolution by natural selection~\cite{b2}, and attempts to determine in a world composed of only two types of teams, which would survive as the "fittest".
As such, this test attempts to determine if a team composed of one "goalie\_agent", two "defender\_agent"s, and two "offensive\_agent"s, is capable of consistently beating a team of reactive agents, specifically these reactive agents are known as "Krislet" agents.
Positive results from this methodology is having an outcome whereupon repeated tests result in the team of reactive agents has been beaten greater than fifty percent of the time.

\subsection{Testing Results (N.S.)}
The results of the four testing methodologies were positive in many manners.
Some testing methodologies were not cohesive with certain agent designs, as a result of their manner of test and this was shown through the testing outcomes.

Each of the variants of agent performed appropriately in the "Single Agent, Single Team" test, however this test was not an optimal test of the "goalie\_agent" or the "defender\_agent".
The "offensive\_agent" functioned appropriately, seeking out the ball, and shooting/scoring repeatedly.
The "goalie\_agent" located its net, and waited in the net for the ball to come within a given distance of it.
This is appropriate output for the test, however this test is not suitable for this agent as much of its actions and reactions are not tested as the ball never enters the distance to cause the agent to perform further actions.
The "defender\_agent" located its defensive position, traversed the field to get to the location, located the ball, and went to the ball.
Following this, the agent entered a constant loop of searching for another player to pass the ball to, which would not end as the nature of the test does not allow for teammates.
This is appropriate output for the test, however this test is not suitable for this agent as much of its actions and reactions are not tested following entering the proximity of the ball.

Each of the variants of agent performed appropriately in the "Utilitarianism" test, however this test was not an optimal test of the "goalie\_agent".
The "offensive\_agent" functioned appropriately "en masse".
This agent continued to consistently seek out the ball and shoot/score repeatedly in a "back and forth" manner, thus passing this test.
The "goalie\_agent" also functioned appropriately "en masse".
All the "goalie\_agent"s sought out their respective nets and waited repeatedly for the ball.
However, this test would not pass, as in teams solely composed of this agent, the games would always end in a tie.
The "defender\_agent" functioned appropriately "en masse".
This agent worked to get its appropriate position, and then get to the ball, following this the agents were able to kick the ball towards other agents in attempts to pass.
This agent would on occasion score as a result of this activity, thus allowing for the test to pass.

Each of the variants of agent performed appropriately in the "teamwork" test.
The "offensive\_agent" functioned appropriately as it was able to locate and track the ball as well as shoot/score goals effectively.
The "goalie\_agent" was able to perform fully in an appropriate manner, as the ball would be moved towards it by other players, and this agent would pass, or clear the ball appropriately given the situations.
The "defender\_agent" functioned appropriately working to get defensive positioning and subsequently attempt to pass the ball appropriately.

The team of developed agents performed appropriately in the "Darwinian Test".
Upon numerous manual tests of the composed team of agents against the team of reactive agents, the composed team of agents succeeded in beating the reactive agents seventy-five percent of the time.


\section{Future Work (J.B.)}
As the aim of this project was to showcase and utilize the Jason BDI framework in the context of RoboCup, there was not much effort put in to optimizing the agents' playstyles.
Future work with this project would be to optimize these agents to better play and better represent their positions.
One such major optimization would be increasing stamina efficiency, especially on the offensive player which is almost always dashing.
The position of the goals relative to the agents could also always be tracked when the agent cannot view them in order to avoid having to spend extra time turning.
Non-goalie agents could also only stay in specifc parts of the field in order to avoid moving back and forth, and the defensive agent could be made to have more accurate passes.
All of these optimizations are only examples of what the team discovered, and examples of what could be worked on using this codebase in the future, however there are most certianly many others which could also be worked on.

\section{Conclusion (W.T.)}
As demonstrated by our implementation of the soccer-playing agents, Jason Belief-Desire-Intention is an effective framework to use for development of simple yet expressive multi-agent reactive planning systems.
By defining the beliefs, rules, goals and plans for agents using the semantics of the AgentSpeak(L) language implemented with the agent architecture, we are able to create agents that exhibit basic behaviors of offensive, defensive and goalkeeper players in soccer.
As previously mentioned, our agents are not well-optimized and their actions are rather simple.
We can continue to make improvements to our plans to make their performance more complex and efficient to take full advantage of the diverse features Jason offers.

\begin{thebibliography}{00}
\bibitem{robocup-objective} Robocup Contributors, ``Objective,''
Robocup. https://www.robocup.org/objective (accessed Dec. 08, 2022).
\bibitem{jason-description} Jason Contributors, ``Description,''
Jason. [Online]. Available:
https://jason.sourceforge.net/wp/description/. [Accessed: 08-Dec-2022].
\bibitem{robocup-simulation-2d} Robocup Contributors, ``RoboCupSoccer ---
Simulation 2D,'' RoboCup. https://www.robocup.org/leagues/24 (accessed Dec. 08,
2022).
\bibitem{jason-manual} R. H. Bordini and J. F. Hübner, ``Jason: A Java-based
interpreter for an extended version of AgentSpeak,'' Feb. 2007. Accessed:
Dec. 08, 2022. [Online]. Available: https://jason.sourceforge.net/Jason.pdf
\bibitem{jason-faq} Jason Contributors, ``Jason FAQ,''
Jason. [Online]. Available:
https://jason.sourceforge.net/doc/faq.html. [Accessed: 08-Dec-2022].
\bibitem{b1} J. S. Mill, ``Utilitarianism,'' London: Parker, Son, and Bourn, 1863.
\bibitem{b2} M. Ruse and R. J. Richards, ''The cambridge companion to the "Origin of species",'' vol. 2. Cambridge: Cambridge University Press, 2009.
\end{thebibliography}

\end{document}
